## 関連研究③

**MindScope: Exploring cognitive biases in LLMs through Multi-Agent Systems**
謝振涛、趙加宝 et al., 2024, arXiv

**どんなもの？**
LLMの認知バイアスを検出するマルチエージェントシステム。72種類のバイアスを調べる質問データと対話シナリオでGPT-4など12モデルを評価。

**先行研究と比べてどこがすごい？**
従来研究より多い72種類を体系的に調査。複数回の対話で静的なテストでは見つからないバイアスを発見。検出精度がGPT-4単体より35%向上。

**技術や手法のキモはどこ？**
RuleGenフレームワーク：記憶・計画・反省・行動の4つのモジュール。調査対象、協力者、司会者の役割分担。自動シナリオ構築と二重チェック。

**どうやって有効だと検証した？**
12モデルの評価で、モデルが大きくなるとバイアスが減ることを確認（Llama2-7b〜70b）。対話ではサンクコスト誤謬や計画誤謬が静���テストより目立つ。GPT-4と人間評価者で高い一致度（Kappa=0.72、精度88%）。

**議論はある？**
IKEA効果は全モデルで低性能。ファインチューニング（Vicunaシリーズ）でバイアスが増える可能性。多言語対応や長時間の対話での安定性が課題。

**次に読むべき論文は？**
認知バイアスの心理学の基礎文献、マルチエージェントの対話生成研究、LLMの安全性・公平性の研究