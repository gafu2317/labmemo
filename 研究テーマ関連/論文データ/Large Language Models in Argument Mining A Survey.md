## 関連研究①

**Large Language Models in Argument Mining: A Survey**
Hao Li, Viktor Schlegel, et al., 2025, arXiv

**どんなもの？**
LLM時代の議論マイニング技術をまとめたサーベイ。250本の論文と40のデータセットを分析し、主張の抽出や品質評価がどう変わったかを整理。

**先行研究と比べてどこがすごい？**
従来のサーベイと違い、プロンプトやRAG、few-shot学習など2021年以降の新しいやり方を体系化。教育・法律・医療への応用例も紹介。

**技術や手法のキモはどこ？**
Chain-of-Thought、RAG、LoRAなどの効率的な学習、合成データ生成、統合的データセット(IAM、ARIES)の活用。

**どうやって有効だと検証した？**
既存研究を分析して、GPT-4のfew-shot学習が従来のfine-tunedモデルと同等以上の性能を出すことを確認。議論品質評価では人間評価者と高い相関(ρ=.46-.93)。

**議論はある？**
LLMがブラックボックスなこと、バイアス、計算コストが課題。多くの研究が特定分野だけの評価で、異なる分野や多言語での性能はまだ不十分。

**次に読むべき論文は？**
Lawrence & Reed (2019)（基礎）、Chen et al. (2024)（LLM応用実験）、Ivanova et al. (2024)（品質評価）